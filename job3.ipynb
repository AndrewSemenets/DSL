{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "job3.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "0DvaiC_rzEHj"
      ],
      "authorship_tag": "ABX9TyPF7xsf9yt07+gP/F+ZtZCU",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AndrewSemenets/DSL/blob/main/job3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u3SjgPdcybY7"
      },
      "source": [
        "\n",
        "\n",
        "```\n",
        "{'toks': set(token), 'vars': dict(var: definition), 'hvar': var}\n",
        "token : (class, value)    # токены\n",
        "class : int\n",
        "value : str\n",
        "var : str                 # имя нетерминала\n",
        "definition : list(rule)\n",
        "rule : list(var | token)  # правая часть правила\n",
        "\n",
        "```\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0DvaiC_rzEHj"
      },
      "source": [
        "Удаление бесполезных нетерминалов:\n",
        "---\n",
        "\n",
        "Непродуктивные: Заполняем список продуктивных нетерминалов, таких, у которых хотя бы в одном правиле все символы - терминалы или уже известные продуктивные нетерминалы. Все нетерминалы не попавшие в список - непродуктивные.\n",
        "\n",
        "Недостижимые: Сначала в множестве достижимых нетерминалов только начальный нетерминал. Добавляем в множество достижимых нетерминалов все нетерминалы из правил нетерминалов, уже входящих в множество достижимых нетерминалов. Повторяем предыдущий шаг, если множество порождающих нетерминалов изменилось.\n",
        "\n",
        "Далее удаляем из грамматики все непродуктивные нетерминалы и правила, в которых они упоминаются. Наконец удаляем из грамматики недостижимые нетерминалы.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SCUXqaYf2xsH"
      },
      "source": [
        "def remove_external_symbs(grammar):\n",
        "\n",
        "  toks = grammar['toks']\n",
        "  vars = grammar['vars']\n",
        "  \n",
        "\n",
        "  #НЕПРОДУКТИВНЫЕ\n",
        "  productive_symbs = set() #список продуктивных нетерминалов\n",
        "  new_prod_found = True #флаг того, найден ли на предыдущей итерации новый продуктивный нетерминал\n",
        "\n",
        "  #функция проверяющая, содержит ли правило только токены и продуктивные нетерминалы\n",
        "  def check_rule(rule) -> bool:\n",
        "    for rule_part in rule:\n",
        "      if rule_part in toks or rule_part in productive_symbs:\n",
        "        pass\n",
        "      else:\n",
        "        return False\n",
        "    return True\n",
        "\n",
        "  #ищем продуктивные нетерминалы\n",
        "  while new_prod_found:\n",
        "    new_prod_found = False\n",
        "    for non_term, definition in vars.items():\n",
        "      if non_term not in productive_symbs:\n",
        "        for rule in definition:\n",
        "          if check_rule(rule):\n",
        "            new_prod_found = True\n",
        "            productive_symbs.add(non_term)\n",
        "            break\n",
        "  \n",
        "  #удаляем из грамматики все упоминания о непродуктивных нетерминалах (сами нетерминалы и правила с ними)\n",
        "  new_vars = dict()\n",
        "  for non_term, definition in vars.items():\n",
        "    if non_term in productive_symbs:\n",
        "      for rule in definition:\n",
        "        if check_rule(rule):\n",
        "          if non_term in new_vars.keys():\n",
        "            new_vars[non_term].append(rule)\n",
        "          else:\n",
        "            new_vars[non_term] = list()\n",
        "            new_vars[non_term].append(rule)\n",
        "\n",
        "  grammar['vars'] = new_vars\n",
        "  #------------------------------------------------------------\n",
        "\n",
        "  #НЕДОСТИЖИМЫЕ\n",
        "  reachable_symbs = set() #список достижимых нетерминалов\n",
        "  reachable_symbs.add(grammar['hvar'])\n",
        "  new_reach_found = True #флаг того, найден ли на предыдущей итерации новый достижимый нетерминал\n",
        "\n",
        "  while new_reach_found:\n",
        "    new_reach_found = False\n",
        "    for non_term, definition in vars.items():\n",
        "      if non_term in reachable_symbs:\n",
        "        for rule in definition:\n",
        "          for elem in rule:\n",
        "            if elem not in toks and elem not in reachable_symbs:\n",
        "              new_reach_found = True\n",
        "              reachable_symbs.add(elem)\n",
        "              \n",
        "              \n",
        "  #удаляем из грамматики все упоминания о недостижимых нетерминалах (сами нетерминалы и правила с ними)\n",
        "  new_vars = dict()\n",
        "  for non_term, definition in vars.items():\n",
        "    if non_term in reachable_symbs:\n",
        "      for rule in definition:\n",
        "        if check_rule(rule):\n",
        "          if non_term in new_vars.keys():\n",
        "            new_vars[non_term].append(rule)\n",
        "          else:\n",
        "            new_vars[non_term] = list()\n",
        "            new_vars[non_term].append(rule)\n",
        "  \n",
        "  grammar['vars'] = new_vars\n",
        "  #------------------------------------------------------------\n",
        "\n",
        "  return grammar"
      ],
      "execution_count": 188,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LDvj3zWFliVL"
      },
      "source": [
        "1) FIRST(X) - все терминалы, с которых могут начинаться всевозможные выводы из X.\n",
        "---\n",
        " \n",
        " Для каждого правила нетерминала Х в множество FIRST(X) будет добавлятся следующее: \n",
        "\n",
        " 1) Если первый символ в правиле - терминал, добавляется этот терминал.\n",
        "\n",
        " 2) Если первый символ в правиле - нетерминал A, то добавляется FIRST(A).\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e-Zie2O_llLI"
      },
      "source": [
        "def first(X, rules, tokens):\n",
        "  res_set = set()\n",
        "  \n",
        "  if len(rules) == 0:\n",
        "    return res_set \n",
        "  \n",
        "  for rule in rules[X]:\n",
        "    if rule[0] in tokens:\n",
        "      res_set.add(rule[0])\n",
        "    else: \n",
        "      res_set = res_set.union(first(rule[0], rules, tokens)) \n",
        "      \n",
        "  return res_set\n"
      ],
      "execution_count": 189,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q01eRAFkUqJD"
      },
      "source": [
        "2) FOLLOW(X) - всевозможные терминалы, которые встречаются после нетерминала Х во всех небесполезных правилах грамматики.\n",
        "--\n",
        "Чтобы найти follow для всех нетерминалов, нужно следовать алгоритму:\n",
        "\n",
        "1)Если в правилах нетерминала A eсть правило  A -> aBb (где а и b - некоторые последовательности нетерминалов и терминалов), то все элементы first(b), за исключением символа конца ввода, добавить к follow(B).\n",
        "\n",
        "2)Если в правилах нетерминала A есть правило A -> aB, то все элементы из follow(A) добавить к follow(B).\n",
        "\n",
        "Повторять пункты 1 и 2, пока результирующий список follow изменяется."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ixlamjSZUqYJ"
      },
      "source": [
        "def follow_for_every_nt(grammar):\n",
        "\n",
        "  def first_for_seq(seq):\n",
        "    result = set()\n",
        "    for symbol in seq:\n",
        "      if symbol in tokens:  \n",
        "        result.add(symbol)\n",
        "        return result\n",
        "      else:\n",
        "        result = set.union(result, dict_of_firsts[symbol])\n",
        "        if endl_symb not in dict_of_firsts[symbol]:\n",
        "          return result\n",
        "        else:\n",
        "          result.remove(endl_symb) \n",
        "\n",
        "    result.add(endl_symb)  \n",
        "    return result\n",
        "  #---------------------------------------\n",
        "\n",
        "  nonterms = grammar['vars'].keys()\n",
        "  tokens = grammar['toks']\n",
        "  start_nt = grammar['hvar']\n",
        "\n",
        "  res_dict = {}\n",
        "  for nt in nonterms:\n",
        "    res_dict[nt] = (set())\n",
        "\n",
        "  dict_of_firsts = {}\n",
        "  for nt in nonterms:\n",
        "    dict_of_firsts[nt] = first(nt, grammar['vars'], tokens)\n",
        "  \n",
        "  endl_symb = (0, 'a')\n",
        "  res_dict[start_nt].add(endl_symb)\n",
        "\n",
        "  changed = True\n",
        "  while changed:\n",
        "    changed = False\n",
        "    for nonterm, rules in grammar['vars'].items():\n",
        "      for rule in rules:\n",
        "        for index, symbol in enumerate(rule):\n",
        "          if symbol in nonterms:\n",
        "            end_seq_firsts = first_for_seq(rule[index+1:])\n",
        "            prev_len = len(res_dict[symbol])\n",
        "\n",
        "            if endl_symb in end_seq_firsts:\n",
        "              end_seq_firsts.remove(endl_symb)\n",
        "              res_dict[symbol] = res_dict[symbol].union(res_dict[nonterm]) #Если в правилах нетерминала A есть правило A -> aB, то все элементы из follow(A) добавить к follow(B).\n",
        "\n",
        "            res_dict[symbol] = res_dict[symbol].union(end_seq_firsts) #Если в правилах нетерминала eсть правило  A -> aBb, то все элементы first(b),\n",
        "                                                                      #за исключением символа конца ввода, добавить к follow(B).\n",
        "\n",
        "            new_len = len(res_dict[symbol])\n",
        "            if new_len != prev_len:\n",
        "              changed = True\n",
        "  return res_dict\n",
        "\n",
        "\n",
        "\n",
        "  "
      ],
      "execution_count": 190,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vNp2sKE07OR1"
      },
      "source": [
        "Пример грамматики и вызов рабочих функций с ней\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0pZMRCCN7PN9",
        "outputId": "e66fca90-dfa6-44fc-8fa3-0c9bc23b7433"
      },
      "source": [
        "grammar1 = {\n",
        "    'toks': set( [\n",
        "        (0, 'a'), \n",
        "        (1, 'b'), \n",
        "        (1, 'c'), \n",
        "        (2, 'd')\n",
        "    ] ),\n",
        "    'vars': {\n",
        "        'A' : [[(1, 'b')], \n",
        "               ['B', 'F'],\n",
        "               [(0, 'a')],\n",
        "               ['W', (1, 'b')]],\n",
        "        'W' : [['F', (1, 'c')],\n",
        "               [(0, 'a')]],\n",
        "        'B' : [['D', (1, 'c')]],\n",
        "        'C' : [['B', 'A', 'W']],\n",
        "        'D' : [['B', (2, 'd')],\n",
        "               ['C', (1, 'b')]],\n",
        "        'F' : [[(2, 'd')],\n",
        "               [(1, 'b'), 'B', 'W'],]\n",
        "    },\n",
        "    'hvar': 'F'\n",
        "}\n",
        "\n",
        "\n",
        "#print(\"Our grammar without the external non-terminals: \", remove_external_symbs(grammar))\n",
        "grammar1 = remove_external_symbs(grammar1)\n",
        "print(grammar1)\n",
        "\n",
        "nt = 'A'\n",
        "print(\"first(\" + nt + \"): \", first(nt, grammar1['vars'], grammar1['toks']))\n",
        "\n",
        "print(\"follow: \", follow_for_every_nt(grammar1))\n"
      ],
      "execution_count": 191,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'toks': {(1, 'b'), (2, 'd'), (0, 'a'), (1, 'c')}, 'vars': {'A': [[(1, 'b')], [(0, 'a')], ['W', (1, 'b')]], 'W': [['F', (1, 'c')], [(0, 'a')]], 'F': [[(2, 'd')]]}, 'hvar': 'F'}\n",
            "first(A):  {(1, 'b'), (2, 'd'), (0, 'a')}\n",
            "follow:  {'A': set(), 'W': {(1, 'b')}, 'F': {(0, 'a'), (1, 'c')}}\n"
          ]
        }
      ]
    }
  ]
}