{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "job2.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyO7orUHs5qEhZVEgytowTeA",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AndrewSemenets/DSL/blob/main/job2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_YvyRoKEeSwf"
      },
      "source": [
        "```\n",
        "{'toks': set(token), 'vars': dict(var: definition), 'hvar': var}\n",
        "token : (class, value)    # токены\n",
        "class : int\n",
        "value : str\n",
        "var : str                 # имя нетерминала\n",
        "definition : list(rule)\n",
        "rule : list(var | token)  # правая часть правила\n",
        "```\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-A3OL-nEhcwg"
      },
      "source": [
        "1) Удаление посторонних нетерминалов:\n",
        "\n",
        "---\n",
        "Заполняем список непосторонних нетерминалов, таких, у которых хотя бы в одном правиле все символы - терминалы или уже известные непосторонние нетерминалы.\n",
        "После удаляем из грамматики все нетерминалы, которые не вошли в этот список, и правила, в которых они упоминаются.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1aZnQBF4e0u8"
      },
      "source": [
        "def remove_external_symbs(grammar):\n",
        "\n",
        "  toks = grammar['toks']\n",
        "  vars = grammar['vars']\n",
        "  non_external_symbs = set() #список непосторонних нетерминалов\n",
        "  new_nonext_found = True #флаг того, найден ли на предыдущей итерации новый непосторонний нетерминал\n",
        "\n",
        "  #функция проверяющая, содержит ли правило только токены и непосторонние нетерминалы\n",
        "  def check_rule(rule) -> bool:\n",
        "    for rule_part in rule:\n",
        "      if rule_part in toks or rule_part in non_external_symbs:\n",
        "        pass\n",
        "      else:\n",
        "        return False\n",
        "    return True\n",
        "\n",
        "  #ищем непосторонние нетерминалы\n",
        "  while new_nonext_found:\n",
        "    new_nonext_found = False\n",
        "    for non_term, definition in vars.items():\n",
        "      if non_term not in non_external_symbs:\n",
        "        for rule in definition:\n",
        "          if check_rule(rule):\n",
        "            new_nonext_found = True\n",
        "            non_external_symbs.add(non_term)\n",
        "            break\n",
        "  \n",
        "  #удаляем из грамматики все упоминания о посторонних нетерминалах (сами нетерминалы и правила с ними)\n",
        "  new_vars = dict()\n",
        "  for non_term, definition in vars.items():\n",
        "    if non_term in non_external_symbs:\n",
        "      for rule in definition:\n",
        "        if check_rule(rule):\n",
        "          if non_term in new_vars.keys():\n",
        "            new_vars[non_term].append(rule)\n",
        "          else:\n",
        "            new_vars[non_term] = list()\n",
        "            new_vars[non_term].append(rule)\n",
        "\n",
        "  grammar['vars'] = new_vars\n",
        "\n",
        "  return grammar\n"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CiNEedFAAnG5"
      },
      "source": [
        "2) Определение исчезающих символов\n",
        "\n",
        "---\n",
        "Пусть пустой токен - токен вида (0, 'а')\n",
        "\n",
        "Находим все нетерминалы, у которых есть хотя бы одно правило, состоящее только из пустых токенов или уже известных исчезающих символов/нетерминалов.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1okZoGg1Atm0"
      },
      "source": [
        "def find_diss_symbs(grammar):\n",
        "  toks = grammar['toks']\n",
        "  vars = grammar['vars']\n",
        "  diss_symbs = set() #список исчезающих символов\n",
        "  new_diss_symb_found = True #флаг того, найден ли на предыдущей итерации новый исчезающий символ\n",
        "\n",
        "  #функция проверяющая, содержит ли правило только пустые токены и исчезающие символы\n",
        "  def check_rule(rule) -> bool:\n",
        "    for rule_part in rule:\n",
        "      if rule_part == (0, 'a') or rule_part in diss_symbs:\n",
        "        pass\n",
        "      else:\n",
        "        return False\n",
        "    return True\n",
        "\n",
        "  while new_diss_symb_found:\n",
        "    new_diss_symb_found = False\n",
        "    for non_term, definition in vars.items():\n",
        "       if non_term not in diss_symbs:\n",
        "         for rule in definition:\n",
        "            if check_rule(rule):\n",
        "              new_diss_symb_found = True\n",
        "              diss_symbs.add(non_term)\n",
        "              break\n",
        "\n",
        "  return diss_symbs"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lzVdzUB85zlt"
      },
      "source": [
        "Пример грамматики и вызов рабочих функций с ней"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CITfhT4UelxS",
        "outputId": "02f004de-19c7-467e-96f1-00100740a23f"
      },
      "source": [
        "grammar = {\n",
        "    'toks': set( [\n",
        "        (0, 'a'), \n",
        "        (1, 'b'), \n",
        "        (1, 'c'), \n",
        "        (2, 'd')\n",
        "    ] ),\n",
        "    'vars': {\n",
        "        'A' : [['A', (1, 'b')], \n",
        "               ['B', 'F'],\n",
        "               ['C', (0, 'a'), 'D'],\n",
        "               ['W', (1, 'b')]],\n",
        "        'W' : [['F', (1, 'c')],\n",
        "               [(0, 'a')]],\n",
        "        'B' : [['D', (1, 'c')]],\n",
        "        'C' : [['B']],\n",
        "        'D' : [['B', (2, 'd')],\n",
        "               ['C', (1, 'b')]],\n",
        "        'F' : [[(2, 'd')],\n",
        "               [(1, 'b'), 'B'],\n",
        "               ['W']]\n",
        "    },\n",
        "    'hvar': 'F'\n",
        "}\n",
        "\n",
        "print(\"Our grammar without the external non-terminals: \", remove_external_symbs(grammar))\n",
        "\n",
        "print(\"Dissaperaing non-terminals: \", find_diss_symbs(grammar))"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Our grammar without the external non-terminals:  {'toks': {(2, 'd'), (1, 'b'), (0, 'a'), (1, 'c')}, 'vars': {'A': [['A', (1, 'b')], ['W', (1, 'b')]], 'W': [['F', (1, 'c')], [(0, 'a')]], 'F': [[(2, 'd')], ['W']]}, 'hvar': 'F'}\n",
            "Dissaperaing non-terminals:  {'F', 'W'}\n"
          ]
        }
      ]
    }
  ]
}